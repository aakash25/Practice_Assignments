{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 1 Average length of the String is:  4.2063492063492065\n",
      "Method 2 Average length of the String is:  4.2063492063492065\n",
      "Elapsed time during the method 1 in seconds: 0.0005091279999760445\n",
      "Elapsed time during the method 2 in seconds: 0.00023671799999647192\n"
     ]
    }
   ],
   "source": [
    "##Python Assignment##\n",
    "#Question 1\n",
    "# Let's take the following string\n",
    "#\" I am very keen in building up my career in Data Science, but not sure from where to start.\n",
    "#If I search the web it throws me thousands of articles, few are relevant others make me confused, again I come around to the same page. \n",
    "#Supervised has provided me a good platform to remove all such qualms which were wrangling in my mind\"\n",
    "\n",
    "#1.1 Consider the above text as a string, figure out the average length of the string.\n",
    "from time import perf_counter \n",
    "string_given= \"I am very keen in building up my career in Data Science, but not sure from where to start. If I search the web it throws me thousands of articles, few are relevant others make me confused, again I come around to the same page. Supervised has provided me a good platform to remove all such qualms which were wrangling in my mind\"\n",
    "string_given\n",
    "#convert the give string into a list\n",
    "splt_string = string_given.split()\n",
    "\n",
    "# Start the stopwatch / counter \n",
    "t1_start = perf_counter()  \n",
    "\n",
    "#Finding out average length\n",
    "all_lengths = []\n",
    "num_of_strings = len(splt_string)\n",
    "num_of_strings\n",
    "\n",
    "for item in splt_string:\n",
    "    string_size = len(item)\n",
    "    all_lengths.append(string_size)\n",
    "\n",
    "avg_length = float(sum(all_lengths)) / float(num_of_strings)\n",
    "print(\"Method 1 Average length of the String is: \",avg_length)\n",
    "t1_stop = perf_counter()\n",
    "\n",
    "#Another optimal way to do it is via map()\n",
    "# Start the stopwatch / counter \n",
    "t2_start = perf_counter() \n",
    "total_avg_length= sum( map(len, splt_string) ) / len(splt_string)\n",
    "print(\"Method 2 Average length of the String is: \",total_avg_length)\n",
    "# Start the stopwatch / counter \n",
    "t2_stop = perf_counter()\n",
    "\n",
    "print(\"Elapsed time during the method 1 in seconds:\", \n",
    "                                        t1_stop-t1_start) \n",
    "print(\"Elapsed time during the method 2 in seconds:\", \n",
    "                                        t2_stop-t2_start) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!--Given string in lower--!\n",
      " i am very keen in building up my career in data science, but not sure from where to start. if i search the web it throws me thousands of articles, few are relevant others make me confused, again i come around to the same page. supervised has provided me a good platform to remove all such qualms which were wrangling in my mind\n"
     ]
    }
   ],
   "source": [
    "#1.2 Lower the text in the string.\n",
    "string_lower=string_given.lower()\n",
    "print(\"!--Given string in lower--!\\n\",string_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!--Clean Text--!\n",
      " I am very keen in building up my career in Data Science but not sure from where to start If I search the web it throws me thousands of articles few are relevant others make me confused again I come around to the same page Supervised has provided me a good platform to remove all such qualms which were wrangling in my mind\n"
     ]
    }
   ],
   "source": [
    "#1.3 Try to get the clean text removing the punctuation from the string.\n",
    "import re\n",
    "splt_string_all = re.split(r'\\W+',string_given)\n",
    "print(\"!--Clean Text--!\\n\",' '.join(splt_string_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 1 Extracted Word from given string is:Data Science\n",
      "Method 2 Extracted Word from given string is:Data Science\n"
     ]
    }
   ],
   "source": [
    "#1.4 Extract word \"Data Science\" from the string.\n",
    "string_join_cleaned=' '.join(splt_string_all)\n",
    "\n",
    "#Find out start index of word Data Science\n",
    "start_index= string_join_cleaned.find('Data Science')\n",
    "#Find out end index of word Data Science\n",
    "end_index= start_index+len('Data Science')\n",
    "\n",
    "#Method 1\n",
    "#Extract the value\n",
    "extracted_value= string_join_cleaned[43:55]\n",
    "frmt_str = 'Method 1 Extracted Word from given string is:%s' % (extracted_value)\n",
    "print(frmt_str)\n",
    "\n",
    "#Method 2 \n",
    "#Extract the value\n",
    "sliceObject=slice(start_index, end_index)\n",
    "frmt_str_2 = 'Method 2 Extracted Word from given string is:%s' % (string_join_cleaned[sliceObject])\n",
    "print(frmt_str_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequnecy of word  I is: 3\n",
      "Frequnecy of word  am is: 1\n",
      "Frequnecy of word  very is: 1\n",
      "Frequnecy of word  keen is: 1\n",
      "Frequnecy of word  in is: 3\n",
      "Frequnecy of word  building is: 1\n",
      "Frequnecy of word  up is: 1\n",
      "Frequnecy of word  my is: 2\n",
      "Frequnecy of word  career is: 1\n",
      "Frequnecy of word  Data is: 1\n",
      "Frequnecy of word  Science is: 1\n",
      "Frequnecy of word  but is: 1\n",
      "Frequnecy of word  not is: 1\n",
      "Frequnecy of word  sure is: 1\n",
      "Frequnecy of word  from is: 1\n",
      "Frequnecy of word  where is: 1\n",
      "Frequnecy of word  to is: 3\n",
      "Frequnecy of word  start is: 1\n",
      "Frequnecy of word  If is: 1\n",
      "Frequnecy of word  search is: 1\n",
      "Frequnecy of word  the is: 2\n",
      "Frequnecy of word  web is: 1\n",
      "Frequnecy of word  it is: 1\n",
      "Frequnecy of word  throws is: 1\n",
      "Frequnecy of word  me is: 3\n",
      "Frequnecy of word  thousands is: 1\n",
      "Frequnecy of word  of is: 1\n",
      "Frequnecy of word  articles is: 1\n",
      "Frequnecy of word  few is: 1\n",
      "Frequnecy of word  are is: 1\n",
      "Frequnecy of word  relevant is: 1\n",
      "Frequnecy of word  others is: 1\n",
      "Frequnecy of word  make is: 1\n",
      "Frequnecy of word  confused is: 1\n",
      "Frequnecy of word  again is: 1\n",
      "Frequnecy of word  come is: 1\n",
      "Frequnecy of word  around is: 1\n",
      "Frequnecy of word  same is: 1\n",
      "Frequnecy of word  page is: 1\n",
      "Frequnecy of word  Supervised is: 1\n",
      "Frequnecy of word  has is: 1\n",
      "Frequnecy of word  provided is: 1\n",
      "Frequnecy of word  a is: 1\n",
      "Frequnecy of word  good is: 1\n",
      "Frequnecy of word  platform is: 1\n",
      "Frequnecy of word  remove is: 1\n",
      "Frequnecy of word  all is: 1\n",
      "Frequnecy of word  such is: 1\n",
      "Frequnecy of word  qualms is: 1\n",
      "Frequnecy of word  which is: 1\n",
      "Frequnecy of word  were is: 1\n",
      "Frequnecy of word  wrangling is: 1\n",
      "Frequnecy of word  mind is: 1\n"
     ]
    }
   ],
   "source": [
    "#1.4 Find the frequency of words used in the string.\n",
    "\n",
    "str_complete_list=splt_string_all\n",
    "\n",
    "#Function which calculates the frequency of a word in given string\n",
    "def WordfrequencyCalculator(str_list):\n",
    "    #Save all distince value in a list . No duplicates\n",
    "    str_no_duplicates=[]\n",
    "    for i in str_list:\n",
    "        if i not in str_no_duplicates:\n",
    "            str_no_duplicates.append(i)\n",
    "    \n",
    "    #print(str_no_duplicates)\n",
    "    \n",
    "    #Now find out the frquency of each word\n",
    "    for i in range(0,len(str_no_duplicates)):\n",
    "        print(\"Frequnecy of word \",str_no_duplicates[i],\"is:\",str_list.count(str_no_duplicates[i]))\n",
    "\n",
    "#Testing\n",
    "#print(str_complete_list.count(\"me\"))---count of word 'me' is 3\n",
    "WordfrequencyCalculator(str_complete_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Pairs are:\n",
      "\n",
      "I\n",
      "in\n",
      "my\n",
      "to\n",
      "the\n",
      "me\n"
     ]
    }
   ],
   "source": [
    "#1.6 Fetch the duplicate pairs used in the string.\n",
    "str_complete_list=splt_string_all\n",
    "\n",
    "#Function which calculates the frequency of a word in given string\n",
    "def DuplicatePairs(str_list):\n",
    "    #Save all distince value in a list . No duplicates\n",
    "    str_no_duplicates=[]\n",
    "    for i in str_list:\n",
    "        if i not in str_no_duplicates:\n",
    "            str_no_duplicates.append(i)\n",
    "    \n",
    "    #print(str_no_duplicates)\n",
    "    \n",
    "    #Now find out the frquency of each word\n",
    "    print(\"Duplicate Pairs are:\\n\")\n",
    "    for i in range(0,len(str_no_duplicates)):\n",
    "        if str_list.count(str_no_duplicates[i])>1:\n",
    "           print(str_no_duplicates[i])\n",
    "\n",
    "DuplicatePairs(str_complete_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am very keen in building up my career in Data Science, but not sure from where to start. If I search the web it throws me thousands of articles, few are relevant others make me confused, again I come around to the same page. Unsupervised has provided me a good platform to remove all such qualms which were wrangling in my mind\n"
     ]
    }
   ],
   "source": [
    "#1.7 Can you change the word \"Supervised\" to \"Unsupervised\" in the string\n",
    "string_original=\"I am very keen in building up my career in Data Science, but not sure from where to start. If I search the web it throws me thousands of articles, few are relevant others make me confused, again I come around to the same page. Supervised has provided me a good platform to remove all such qualms which were wrangling in my mind\"\n",
    "string_replaced= string_original.replace('Supervised','Unsupervised')\n",
    "print(string_replaced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strig splitted based on dot operator:\n",
      " ['I am very keen in building up my career in Data Science, but not sure from where to start', ' If I search the web it throws me thousands of articles, few are relevant others make me confused, again I come around to the same page', ' Supervised has provided me a good platform to remove all such qualms which were wrangling in my mind']\n"
     ]
    }
   ],
   "source": [
    "#1.8 Splitting of the string with a dot operator(.)\n",
    "string_split_dot= string_original.split('.')\n",
    "print(\"Strig splitted based on dot operator:\\n\",string_split_dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words from the string which ends with e are:\n",
      " ['Science', 'sure', 'where', 'the', 'me', 'are', 'make', 'me', 'come', 'the', 'same', 'page', 'me', 'remove', 'were']\n"
     ]
    }
   ],
   "source": [
    "#1.9 Find the words from the string which ends with \"e\"\n",
    "#first get all string in a list without any punctuation\n",
    "splt_string_all = re.split(r'\\W+',string_original)\n",
    "str_complete_list=splt_string_all\n",
    "\n",
    "#Function which find the words from the string which end with a particular character\n",
    "def FindWordsWithAEndChar(str_list,end_char):    \n",
    "    temp_list=[]\n",
    "    for i in str_list:\n",
    "        if i[len(i)-1]==end_char:\n",
    "            temp_list.append(i)\n",
    "    print(\"Words from the string which ends with e are:\\n\",temp_list)\n",
    "\n",
    "FindWordsWithAEndChar(str_complete_list,'e')\n",
    "#FindWordsWithAEndChar(str_complete_list,'d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of a's used in the string: 22\n"
     ]
    }
   ],
   "source": [
    "#Figure out number of a's used in the string.\n",
    "#first get all string in a list without any punctuation\n",
    "splt_string_all = re.split(r'\\W+',string_original)\n",
    "str_complete_list=splt_string_all\n",
    "\n",
    "def FindNoOfOccuranceOfaChar(str_list,char):    \n",
    "    sum=0;\n",
    "    for i in str_list:\n",
    "        sum=sum+i.count(char)\n",
    "    print(\"Number of a's used in the string:\",sum)\n",
    "\n",
    "FindNoOfOccuranceOfaChar(str_complete_list,'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'apple': 0.25, 'sugar': 0.5, 'rice': 2.5, 'milk': 2.5, 'egg': 1}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Questions on Dictionary\n",
    "\n",
    "#In the weekend , I purchased 250g of apple, 500g of sugar, 2.5 kg of rice, 2.5 litres of milk and finally 1 dozen of egg.\n",
    "#Question 1 Can you help me frame the above purchase in the form of dictionary with commodities as keys to it.\n",
    "commodities_dictonary={'apple':0.250,'sugar':0.5,'rice':2.5,'milk':2.5,'egg':1}\n",
    "commodities_dictonary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'apple': 0.25, 'sugar': 0.5, 'rice': 2.5, 'milk': 2.5, 'egg': 1, 'atta': 1}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I forgot to mention another item, 1kg of atta packet. Can you also add it ?\n",
    "commodities_dictonary['atta']= 1\n",
    "commodities_dictonary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'apple': 0.25, 'sugar': 0.5, 'rice': 1, 'milk': 2.5, 'egg': 1, 'atta': 1}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Instead of 2kg of rice, I bought only 1kg of rice. Can you change the corresponding value ?\n",
    "commodities_dictonary['rice']= 1\n",
    "commodities_dictonary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('apple', 0.25)\n",
      "('sugar', 0.5)\n",
      "('rice', 1)\n",
      "('milk', 2.5)\n",
      "('egg', 1)\n",
      "('atta', 1)\n"
     ]
    }
   ],
   "source": [
    "#Can you list out all these items using a loop.\n",
    "\n",
    "for item in commodities_dictonary.items():\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'apple': 220, 'sugar': 43, 'rice': 45, 'milk': 30, 'egg': 60, 'atta': 120}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#However, the cost of 1 kg apple is Rs.220, 1 kg of sugar is Rs.43, 1 Kg of rice is Rs. 45, 1 litre of milk is Rs.30 and 1 dozen of egg is Rs. 60.\n",
    "\n",
    "pricing_dictionary={'apple':220,'sugar':43,'rice':45,'milk':30,'egg':60,'atta': 120}\n",
    "pricing_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Total Bill-----\n",
      "\n",
      "Item 1: apple Quantity:  0.25 Price:  55.0 Net Rate:  220\n",
      "Item 1: sugar Quantity:  0.5 Price:  21.5 Net Rate:  43\n",
      "Item 1: rice Quantity:  1 Price:  45 Net Rate:  45\n",
      "Item 1: milk Quantity:  2.5 Price:  75.0 Net Rate:  30\n",
      "Item 1: egg Quantity:  1 Price:  60 Net Rate:  60\n",
      "Item 1: atta Quantity:  1 Price:  120 Net Rate:  120\n",
      "\n",
      " Total Bill is:  376.5\n",
      "----------Thank You Visit Again---\n"
     ]
    }
   ],
   "source": [
    "print('---------Total Bill-----\\n')\n",
    "Total_Bill=0\n",
    "for item in commodities_dictonary.items():\n",
    "    print('Item 1:',item[0] ,'Quantity: ', item[1], 'Price: ',item[1]*pricing_dictionary[item[0]], 'Net Rate: ',pricing_dictionary[item[0]])\n",
    "    Total_Bill= Total_Bill+item[1]*pricing_dictionary[item[0]]\n",
    "print('\\n Total Bill is: ',Total_Bill)\n",
    "print('----------Thank You Visit Again---')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Questions on List\n",
    "\n",
    "#Listed are top AI companies of world\n",
    "AI_companies= ['Amazon','Facebook','HiSilicon','Google','Apple','Microsoft','SenseTime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Amazon',\n",
       " 'Apple',\n",
       " 'Facebook',\n",
       " 'Google',\n",
       " 'HiSilicon',\n",
       " 'Microsoft',\n",
       " 'SenseTime']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sort the list in ascending order\n",
    "AI_companies.sort()\n",
    "AI_companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Amazon', 'Apple', 'Facebook', 'Google', 'HiSilicon', 'Microsoft', 'SenseTime', 'Nvidia', 'OpenAI', 'Qualcomm', 'Reliance']\n",
      "['Amazon', 'Apple', 'Facebook', 'Google', 'HiSilicon', 'Microsoft', 'Nvidia', 'OpenAI', 'Qualcomm', 'Reliance', 'SenseTime']\n"
     ]
    }
   ],
   "source": [
    "#Add multiple companies at once 'Nvidia', 'OpenAI' , 'Qualcomm' and 'Reliance' to the list\n",
    "AI_companies.extend(['Nvidia','OpenAI','Qualcomm','Reliance'])\n",
    "print(AI_companies)\n",
    "AI_companies.sort()\n",
    "print(AI_companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['amazon', 'apple', 'facebook', 'google', 'hisilicon', 'microsoft', 'nvidia', 'openai', 'qualcomm', 'reliance', 'sensetime']\n",
      "['amazon', 'apple', 'facebook', 'google', 'hisilicon', 'microsoft', 'nvidia', 'openai', 'qualcomm', 'reliance', 'sensetime']\n"
     ]
    }
   ],
   "source": [
    "#Lower the list using List comprehension\n",
    "AI_companies_lower=[x.lower() for x in AI_companies ]\n",
    "print(AI_companies_lower)\n",
    "\n",
    "#using and lambda function\n",
    "\n",
    "AI_companies_lower_map= list(map(lambda x:x.lower(),AI_companies))\n",
    "print(AI_companies_lower_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Amazon', 'Apple', 'Facebook', 'Google', 'HiSilicon', 'Microsoft', 'Nvidia', 'OpenAI', 'Qualcomm', 'SenseTime']\n"
     ]
    }
   ],
   "source": [
    "#Elimiate 'Reliance' from the list\n",
    "AI_companies.remove('Reliance')\n",
    "print(AI_companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Facebook', 'Google', 'Microsoft']\n",
      "['Facebook', 'Google', 'Microsoft']\n"
     ]
    }
   ],
   "source": [
    "#Extract 'Facebook', 'Google' and 'Microsoft' using a single command\n",
    "print([AI_companies[x] for x in [2,3,5]])\n",
    "test_map= list(map(lambda x:AI_companies[x],[2,3,5]))\n",
    "print(test_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(220, 43, 45, 30, 60, 120)\n"
     ]
    }
   ],
   "source": [
    "#Questions on Tuple\n",
    "\n",
    "#Consider the above standard price problem statement and place the prices in the form of the tuple.\n",
    "commodities_price_tuple=(220,43,45,30,60,120)\n",
    "print(commodities_price_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min Value in tuple:  30   Max Value in tuple:  220\n"
     ]
    }
   ],
   "source": [
    "#Find out the min and max price among them.\n",
    "print('Min Value in tuple: ',min(commodities_price_tuple),' ','Max Value in tuple: ',max(commodities_price_tuple))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Amazon', 'Apple', 'Facebook', 'Google', 'HiSilicon', 'Microsoft', 'Nvidia', 'OpenAI', 'Qualcomm', 'SenseTime')\n"
     ]
    }
   ],
   "source": [
    "#Also, convert the above \"AI_companies\" list to a tuple.\n",
    "AI_companies_tuple=('Amazon', 'Apple', 'Facebook', 'Google', 'HiSilicon', 'Microsoft', 'Nvidia', 'OpenAI', 'Qualcomm', 'SenseTime')\n",
    "print(AI_companies_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(220, 43, 45, 30, 60, 120, 'Amazon', 'Apple', 'Facebook', 'Google', 'HiSilicon', 'Microsoft', 'Nvidia', 'OpenAI', 'Qualcomm', 'SenseTime')\n"
     ]
    }
   ],
   "source": [
    "#Combine two above tuples to a single tuple.\n",
    "new_tuple_combined=commodities_price_tuple+AI_companies_tuple\n",
    "print(new_tuple_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of commodities_price_tuple is:  6\n",
      "Length of AI_companies_tuple is:  10\n",
      "AI_companies_tuple length is more than commodities tuple\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Compare the length of two tuples.\n",
    "print('Length of commodities_price_tuple is: ', len(commodities_price_tuple))\n",
    "print('Length of AI_companies_tuple is: ', len(AI_companies_tuple))\n",
    "if(len(AI_companies_tuple)>len(commodities_price_tuple)):\n",
    "    print('AI_companies_tuple length is more than commodities tuple')\n",
    "    \n",
    "elif(len(AI_companies_tuple)==len(commodities_price_tuple)):\n",
    "    print('Both are of same length')\n",
    "else:\n",
    "    print('commodities length is more than AI_companies_tuple tuple') \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
